# Below is example config yaml file for QSIPrep:

cli_call: |
    -v -v \
    -w ${PWD}/.git/tmp/wkdir \
    --n_cpus $NSLOTS \
    --stop-on-first-crash \
    --fs-license-file code/license.txt \
    --skip-bids-validation \
    --unringing-method mrdegibbs \
    --output-resolution 2.0

# You should not have flags of : `--participant-label`, or `--bids-filter-file`!

singularity_run:
    -v: "-v"
    -w: "$BABS_TMPDIR"   # this is a placeholder. To be changed to `${PWD}/.git/tmp/wkdir`
    --n_cpus: "$NSLOTS"   # `$NSLOTS` can be recognized by SGE; if you're using Slurm clusters please change to Slurm version!
    --omp-nthreads: "3"   # without this, only run single-threaded jobs (N=`--n_cpus`) at once
    --stop-on-first-crash: ""
    --fs-license-file: "/cbica/projects/BABS/software/FreeSurfer/license.txt"  # path to FS license file
    --skip-bids-validation: Null  # Null or NULL is also a placeholder
    --unringing-method: "mrdegibbs"
    --output-resolution: "2.0"
    --sloppy: ""    # ADD THIS WHEN TESTING
    --hmc-model: "none"   # ADD THIS WHEN TESTING
    --dwi-only: ""   # ADD THIS WHEN TESTING

# Output foldername(s) to be zipped, and the BIDS App version to be included in the zip filename(s):
zip_foldernames:
    qsiprep: "0-16-0RC3"     # folder 'qsiprep' will be zipped into 'sub-xx_ses-yy_qsiprep-0-16-0RC3.zip'

cluster_resources:
    interpreting_shell: /bin/bash  # `#$ -S /bin/bash` on cubic
    hard_memory_limit: 32G   # `#$ -l h_vmem=32G` on cubic
    temporary_disk_space: 200G   # `#$ -l tmpfree=200G` on cubic
    number_of_cpus: "6"    # `#$ -pe threaded 6` on cubic
    customized_text: |
        #$ -R y
        #$ -l hostname=!compute-fed*
# Notes: Above `customized_text` is Penn Med CUBIC cluster specific.
#   So it's probably not relevant for other clusters

# Users need to add their customized bash command below,
#   they will be used as preambles in `participant_job.sh`
#   the commands should not be quoted!
script_preamble: |
    source ${CONDA_PREFIX}/bin/activate mydatalad    # Penn Med CUBIC cluster; replace 'mydatalad' with your conda env name
    echo "I am running BABS."   # this is an example command to show how to add another line; not necessary to include.

# Where to run the jobs:
job_compute_space: "${CBICA_TMPDIR}"   # Penn Med CUBIC cluster tmp space

required_files:
    $INPUT_DATASET_#1:
        - "dwi/*_dwi.nii*"   # QSIPrep
