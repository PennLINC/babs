# Below is example config yaml file for toy BIDS App:

singularity_run:
    # --no-zipped: ""  # for raw BIDS dataset
    --zipped: ""    # for zipped input dataset
    -v: ""

# Output foldername(s) to be zipped, and the BIDS App version to be included in the zip filename(s):
zip_foldernames:
    toybidsapp: "0-0-7"   # folder 'toybidsapp' will be zipped into 'sub-xx_ses-yy_toybidsapp-0-0-7.zip'


cluster_resources:
    interpreting_shell: /bin/bash   # "-S /bin/bash" on cubic
    hard_memory_limit: 25G   # "-l h_vmem=25G" on cubic
    # soft_memory_limit: 23.5G   # "-l s_vmem=23.5G" on cubic   # no need to set s_vmem
    temporary_disk_space: 50G   # "-l tmpfree=200G" on cubic  # this is highly-recommended on cubic
    customized_text: |
        #$ -R y

# Users need to add their customized bash command below,
#   they will be used as preambles in `participant_job.sh`
#   the commands should not be quoted!
script_preamble: |
    source ${CONDA_PREFIX}/bin/activate mydatalad    # Penn Med CUBIC cluster; replace 'mydatalad' with your conda env name

# Where to run the jobs:
job_compute_space: "${CBICA_TMPDIR}"   # Penn Med CUBIC cluster tmp space

# Below is to filter out subjects (or sessions)
#   right now we only filter based on unzipped dataset
# required_files:
#     $INPUT_DATASET_#1:
#         - ""

