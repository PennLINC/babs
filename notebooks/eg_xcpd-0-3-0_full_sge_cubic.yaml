# Below is example config yaml file for XCP-D:
# THIS IS STILL IN PROGRESS...

cli_call: |
    --despike --lower-bpf 0.01 --upper-bpf 0.08 --participant_label $subid -p 36P -f 10 -w ${PWD}/.git/tmp/wkdir --nthreads 6


singularity_run:
    --despike: ""
    --lower-bpf: 0.01
    --upper-bpf: 0.08
    -p: 36P
    -f: 10
    -w: "$BABS_TMPDIR"   # this is a placeholder.
    # --nthreads: 6

# Output foldername(s) to be zipped, and the BIDS App version to be included in the zip filename(s):
zip_foldernames:
    xcp_d: "0-3-0"     # folder 'xcp_d' will be zipped into 'sub-xx_ses-yy_xcp_d-0-3-0.zip'

cluster_resources:
    interpreting_shell: /bin/bash   # "-S /bin/bash" on cubic
    hard_memory_limit: 32G   # "-l h_vmem=xG" on cubic
    temporary_disk_space: 200G   # "-l tmpfree=200G" on cubic
    #number_of_cpus: "6"   # "-pe threaded 6" on cubic
    hard_runtime_limit: "24:00:00"   # "-l h_rt=24:00:00" on cubic
    customized_text: |
        #$ -R y
        #$ -l hostname=!compute-fed*
# Notes: Above `customized_text` is Penn Med CUBIC cluster specific.
#   So it's probably not relevant for other clusters

# Users need to add their customized bash command below,
#   they will be used as preambles in `participant_job.sh`
#   the commands should not be quoted!
script_preamble: |
    source ${CONDA_PREFIX}/bin/activate mydatalad    # Penn Med CUBIC cluster; replace 'mydatalad' with your conda env name
    echo "I am running BABS."   # this is an example command to show how to add another line; not necessary to include.

# Where to run the jobs:
job_compute_space: "${CBICA_TMPDIR}"   # Penn Med CUBIC cluster tmp space
